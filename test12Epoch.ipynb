{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test12Epoch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMNv6hiDXS94lBgOnBCZ50n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fix27/Colab-Store/blob/main/test12Epoch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV9fVCE2ND_P",
        "outputId": "861d2bfe-2e0d-4f83-cb31-a74d8e614ca1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#!wget https://s3.amazonaws.com/img-datasets/mnist.npz\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()\n",
        "# You can change the directory name\n",
        "LOG_DIR = 'tb_logs'\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "if not os.path.exists(LOG_DIR):\n",
        "  os.makedirs(LOG_DIR)\n",
        "  \n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR))\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "tbCallBack = TensorBoard(log_dir=LOG_DIR, \n",
        "                         histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         batch_size=batch_size,\n",
        "                         write_images=True)\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[tbCallBack])\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])    "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/lib/python3.6/json/__init__.py\", line 299, in load\n",
            "    parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
            "  File \"/usr/lib/python3.6/json/__init__.py\", line 354, in loads\n",
            "    return _default_decoder.decode(s)\n",
            "  File \"/usr/lib/python3.6/json/decoder.py\", line 339, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/usr/lib/python3.6/json/decoder.py\", line 357, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
            "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n",
            "Epoch 1/12\n",
            "  1/469 [..............................] - ETA: 0s - loss: 2.2932 - accuracy: 0.1875WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "  2/469 [..............................] - ETA: 12s - loss: 2.2982 - accuracy: 0.1445WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0113s vs `on_train_batch_end` time: 0.0404s). Check your callbacks.\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 2.2726 - accuracy: 0.1534 - val_loss: 2.2238 - val_accuracy: 0.4113\n",
            "Epoch 2/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 2.2009 - accuracy: 0.2682 - val_loss: 2.1332 - val_accuracy: 0.6076\n",
            "Epoch 3/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 2.1085 - accuracy: 0.3848 - val_loss: 2.0144 - val_accuracy: 0.6935\n",
            "Epoch 4/12\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 1.9879 - accuracy: 0.4746 - val_loss: 1.8604 - val_accuracy: 0.7380\n",
            "Epoch 5/12\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 1.8367 - accuracy: 0.5383 - val_loss: 1.6725 - val_accuracy: 0.7571\n",
            "Epoch 6/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 1.6701 - accuracy: 0.5756 - val_loss: 1.4690 - val_accuracy: 0.7771\n",
            "Epoch 7/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 1.5045 - accuracy: 0.6082 - val_loss: 1.2729 - val_accuracy: 0.7926\n",
            "Epoch 8/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 1.3507 - accuracy: 0.6380 - val_loss: 1.1022 - val_accuracy: 0.8063\n",
            "Epoch 9/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 1.2204 - accuracy: 0.6612 - val_loss: 0.9638 - val_accuracy: 0.8176\n",
            "Epoch 10/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 1.1183 - accuracy: 0.6820 - val_loss: 0.8547 - val_accuracy: 0.8279\n",
            "Epoch 11/12\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 1.0319 - accuracy: 0.7030 - val_loss: 0.7696 - val_accuracy: 0.8348\n",
            "Epoch 12/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.9643 - accuracy: 0.7171 - val_loss: 0.7029 - val_accuracy: 0.8431\n",
            "Test loss: 0.7028656601905823\n",
            "Test accuracy: 0.8431000113487244\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}